---
title: "Stat 445 Final"
author: "Amber Duevel"
date: "12/13/2022"
output: html_document
---
```{r}
library(dplyr)
library(readxl)
library(tidyverse)
library(car)
library(GGally)
library(AICcmodavg)
library(asbio)

library(lattice)
```

```{r}
MIX<-read_xlsx("MIX_model_original_data.xlsx")
MC<-read_xlsx("MC_model_original_data.xlsx")
```

```{r Dependent Variables for MC}
#Dependent Variable: ELISA_microcystin_ugL 
#Dependent Variable: ELISA_MC+ANA+SXT
```

```{r}
MC$Year = format(as.Date(MC$DateTime, format = "%Y-%m-%d"), "%Y")
MC_new = MC[!is.na(MC$'ELISA_MC+ANA+SXT'),]
MC_clean = MC_new %>% select_if(~ !any(is.na(.)))
MC_clean$Year = format(as.Date(MC_clean$DateTime, format = "%Y-%m-%d"), "%Y")
MC_clean = MC_clean %>% group_by(Year, siteID)

MIX$Year = format(as.Date(MIX$DateTime, format = "%Y-%m-%d"), "%Y")
MIX = MIX %>% group_by(Year, siteID)
MIX_new = MIX[!is.na(MIX$'ELISA_MC+ANA+SXT'),]
MIX_clean = MIX_new %>% select_if(~ !any(is.na(.)))
MIX_clean$Year = format(as.Date(MIX_clean$DateTime, format = "%Y-%m-%d"), "%Y")

```
##Creating Table 2
The report was unclear about how they calculated the minimum, maximum, and median for each site ID by year. The report stated that their sample size was n=41 for each site ID. That means they worked with the original data collected. If we did this a lot of the statistics would come back as NAs due to a significant amount of NAs in the data collected. We decided to work with the original data but calculate the statistics without the NAs in order to produce the table. This is why our numbers don't match the table in the report.
```{r}
MC <- MC %>% group_by(Year, siteID)
Table_1 <- MC %>% summarise(max_pH=max(pH, na.rm=TRUE), min_pH=min(pH, na.rm=TRUE), median_pH=median(pH, na.rm=TRUE)) 
Table_2 <- MC %>% summarise(max_WT=max(WTemp_C, na.rm=TRUE), min_WT=min(WTemp_C, na.rm=TRUE), median_WT=median(WTemp_C, na.rm=TRUE)) 
Table_3 <- MC %>% summarise(max_D=max(Secchi_meters, na.rm=TRUE), min_D=min(Secchi_meters, na.rm=TRUE), median_D=median(Secchi_meters, na.rm=TRUE)) 
Table_4 <- MC %>% summarise(max_SC=max(SpCond_uScm, na.rm=TRUE), min_SC=min(SpCond_uScm, na.rm=TRUE), median_SC=median(SpCond_uScm, na.rm=TRUE)) 
Table_5 <- MC %>% summarise(max_NH3=max(Ammonia_mgL_LAG, na.rm=TRUE), min_NH3=min(Ammonia_mgL_LAG, na.rm=TRUE), median_NH3=median(Ammonia_mgL_LAG, na.rm=TRUE)) 
Table_6 <- MC %>% summarise(max_NN=max(Nox_mgL_LAG, na.rm=TRUE), min_NN=min(Nox_mgL_LAG, na.rm=TRUE), median_NN=median(Nox_mgL_LAG, na.rm=TRUE)) 
Table_7 <- MC %>% summarise(max_OP=max(OrthoP_mgL_LAG, na.rm=TRUE), min_OP=min(OrthoP_mgL_LAG, na.rm=TRUE), median_OP=median(OrthoP_mgL_LAG, na.rm=TRUE)) 
Table_8 <- MC %>% summarise(max_TP=max(TP_mgL_LAG, na.rm=TRUE), min_TP=min(TP_mgL_LAG, na.rm=TRUE), median_TP=median(TP_mgL_LAG, na.rm=TRUE)) 
Table_9 <- MC %>% summarise(max_TN=max(TN_mgL_LAG, na.rm=TRUE), min_TN=min(TN_mgL_LAG, na.rm=TRUE), median_TN=median(TN_mgL_LAG, na.rm=TRUE)) 
Table_10 <- MC %>% summarise(max_NiP=max(NtoP_ratio_LAG, na.rm=TRUE), min_NiP=min(NtoP_ratio_LAG, na.rm=TRUE), median_NiP=median(NtoP_ratio_LAG, na.rm=TRUE))

Table <- merge(Table_1,Table_2, by=c("siteID", "Year"))
Table <- merge(Table,Table_3, by=c("siteID", "Year"))
Table <- merge(Table,Table_4, by=c("siteID", "Year"))
Table <- merge(Table,Table_5, by=c("siteID", "Year"))
Table <- merge(Table,Table_6, by=c("siteID", "Year"))
Table <- merge(Table,Table_7, by=c("siteID", "Year"))
Table <- merge(Table,Table_8, by=c("siteID", "Year"))
Table <- merge(Table,Table_9, by=c("siteID", "Year"))
Table <- merge(Table,Table_10, by=c("siteID", "Year"))

```

##Creating Table 3
The article was unclear about what values they used in order to calculate the statistics in table 3. For Anatoxin, they used a minimum reporting limit for their values which we suspect to be 0.15. When we went to go calculate the minimum for our data it didn't match theirs due to this. 
```{r}
MC_Table3<- MC_clean %>% group_by(Year, siteID)
Table3 = MC_Table3 %>% summarise(min_Anatoxin=min(ELISA_anatoxin_ugL), max_Anatoxin=max(ELISA_anatoxin_ugL), med_Anatoxin=median(ELISA_anatoxin_ugL), min_Microcystin=min(ELISA_microcystin_ugL), max_Microcystin=max(ELISA_microcystin_ugL), med_Microcystin=median(ELISA_microcystin_ugL), min_Saxitoxin=min(ELISA_saxitoxin_ugL), max_Saxitoxin=max(ELISA_saxitoxin_ugL), med_Saxitoxin=median(ELISA_saxitoxin_ugL))

```

##Variable Selection
In this section we looked at the article to see what variables they for sure didn't use in their model. We also looked to see if there were any repeating values and removed those variables too. This got us down to 43 variables. We created a model with these 43 variables and ran a VIF test. The article stated that they got rid of any variables that had a VIF value higher than five. This got us to 25 variables. When running the VIF test, we had some variables with really high VIF scores but the article kept those variables in their model. Due to the article being unclear about this we kept those variables in the model even though they had a high VIF value. With the 25 variables we were unable to figure out how they got down to their specific variables so we jumped to the next step.

```{r}
#The variables that are included in Table 4 include Water temperature(WT) Specific conductance(SC), Total phosphorus(TP), "the plank one"(Plank_mcyE), "the micro one"(Micro_mcyE), Anatoxin(anaC), Saxitoxin(sxtA), Wind direction(WindDir), Lake level for 7 days(LL_7day), Lake level spring average(LL_Spring), Lake level 14 days(LL_14day)

MC_clean2 = MC_clean %>% select(-c("ELISA_anatoxin_ugL", "Ammonia_mgL_LAG", "Nox_mgL_LAG", "Nitrite_mgL_LAG", "Nitrate_mgL_LAG", "OrthoP_mgL_LAG", "SXTx100", "DateTime", "MCx12.5", "siteID", "Year", "Ana_mcyE_cp100mL_LAG", "LkLevelChg7day"))

#Ana_mcYE had 21/50 repeated values
#LkLevelChg24_Ave7day has perfect colinearity with LkLevelChg7day so took out LkLevelChg7day since its not in the final model
#took out Rain48W because it was highly correlated with Rain72W

model1 = lm(ELISA_microcystin_ugL ~ WTemp_C + Secchi_meters + pH + SpCond_uScm + TP_mgL_LAG + TN_mgL_LAG + NtoP_ratio_LAG + Micro_mcyE_cp100mL_LAG + Plank_mcyE_cp100mL_LAG + anaC_cp100mL_LAG + sxtA_cp100mL_LAG + WindSpInst_mph + WindDirInst_deg + WindSpAnt24_mph + WindDirAnt24_deg + RainD_1 + RainD_2 + RainD_3 + Rain48W_in + Rain72W_in + Sum7d_precip + Sum14d_precip + BarPressInst_inhg + changeBP + LkLevelChg24_ft + LkLevelChg14day + LkLevelChg24_Ave7day + LkLevelChg24_Ave7dayABS + LkLevel_dev_springave + PAR_1dSUM + PAR_3dAVG + PAR_5dAVG + PAR_7dAVG + PAR_14dAVG + Dis_dm1 + Dis_dm2 + Dis_dm3 + Dis_7dAve + Dis_14dAve + Dis_30dAve, data = MC_clean2)
summary(model1)
#vif(model1)

#corr_matrix = cor(MC_clean2)
#corrplot(corr_matrix)

#cor.test(MC_clean2$Rain48W_in, MC_clean2$Dis_30dAve)

#took out Rain72 and RainD1 because of high colinearity

model2_MC = lm(ELISA_microcystin_ugL ~ WTemp_C + Secchi_meters + pH + SpCond_uScm + TP_mgL_LAG + NtoP_ratio_LAG + Micro_mcyE_cp100mL_LAG + Plank_mcyE_cp100mL_LAG + anaC_cp100mL_LAG + sxtA_cp100mL_LAG + WindSpInst_mph + WindDirInst_deg + WindSpAnt24_mph + WindDirAnt24_deg + Rain48W_in + Sum14d_precip + BarPressInst_inhg + changeBP + LkLevelChg14day + LkLevelChg24_Ave7day + LkLevelChg24_Ave7dayABS + LkLevel_dev_springave + PAR_1dSUM, data = MC_clean2)

summary(model2_MC)
vif(model2_MC)

#brings it down to like 25 variables

MC_clean3 <- MC_clean2 %>% select(c("ELISA_microcystin_ugL", "WTemp_C", "Secchi_meters", "pH", "SpCond_uScm", "TP_mgL_LAG", "NtoP_ratio_LAG", "Micro_mcyE_cp100mL_LAG", "Plank_mcyE_cp100mL_LAG", "anaC_cp100mL_LAG", "sxtA_cp100mL_LAG", "WindSpInst_mph", "WindDirInst_deg", "WindSpAnt24_mph", "WindDirAnt24_deg", "Rain48W_in", "Sum14d_precip", "BarPressInst_inhg", "changeBP", "LkLevelChg14day", "LkLevelChg24_Ave7day", "LkLevelChg24_Ave7dayABS", "LkLevel_dev_springave", "PAR_1dSUM"))

```

##Step Algorithm
We did a step algorithm of our model with 25 variables. The step algorithm we used was the backward direction one. This got us down to 10 variables in our final model. For the creation of table 4, we were missing 3 variables that they used. We decided to jump to the next step and put in the three missing variables due to the article being unclear here.

```{r}
colnames(MC_clean2)[4] = "ELISA_MC_ANA_SXT"
model3_MIX = lm(ELISA_MC_ANA_SXT ~ WTemp_C + Secchi_meters + pH + SpCond_uScm + TP_mgL_LAG + NtoP_ratio_LAG + Micro_mcyE_cp100mL_LAG + Plank_mcyE_cp100mL_LAG + anaC_cp100mL_LAG + sxtA_cp100mL_LAG + WindSpInst_mph + WindDirInst_deg + WindSpAnt24_mph + WindDirAnt24_deg + RainD_1 + Sum14d_precip + BarPressInst_inhg + changeBP + LkLevelChg14day + LkLevelChg24_Ave7day + LkLevelChg24_Ave7dayABS + LkLevel_dev_springave + PAR_1dSUM, data = MC_clean2)

summary(model3_MIX)
vif(model3_MIX)

MC_clean3 = MC_clean2 %>% select("ELISA_microcystin_ugL", "WTemp_C", "Secchi_meters", "pH", "SpCond_uScm", "TP_mgL_LAG", "NtoP_ratio_LAG", "Micro_mcyE_cp100mL_LAG", "Plank_mcyE_cp100mL_LAG", "anaC_cp100mL_LAG", "sxtA_cp100mL_LAG", "WindSpInst_mph", "WindDirInst_deg",  "WindSpAnt24_mph", "WindDirAnt24_deg", "Rain48W_in", "Sum14d_precip", "BarPressInst_inhg", "changeBP", "LkLevelChg14day",  "LkLevelChg24_Ave7day", "LkLevelChg24_Ave7dayABS", "LkLevel_dev_springave", "PAR_1dSUM")

MIX_clean4 = MC_clean2 %>% select("ELISA_MC_ANA_SXT", "WTemp_C", "Secchi_meters", "pH", "SpCond_uScm", "TP_mgL_LAG", "NtoP_ratio_LAG", "Micro_mcyE_cp100mL_LAG", "Plank_mcyE_cp100mL_LAG", "anaC_cp100mL_LAG", "sxtA_cp100mL_LAG", "WindSpInst_mph", "WindDirInst_deg", "WindSpAnt24_mph", "WindDirAnt24_deg", "RainD_1", "Sum14d_precip", "BarPressInst_inhg", "changeBP", "LkLevelChg14day", "LkLevelChg24_Ave7day", "LkLevelChg24_Ave7dayABS", "LkLevel_dev_springave", "PAR_1dSUM")
```

```{r}
step(model2_MC, direction="backward")

model3_MC<-lm(ELISA_microcystin_ugL ~ WTemp_C + SpCond_uScm + TP_mgL_LAG + Micro_mcyE_cp100mL_LAG + Plank_mcyE_cp100mL_LAG + WindDirInst_deg + LkLevelChg14day + LkLevelChg24_Ave7day +  LkLevel_dev_springave, data = MC_clean3)

Table4 = data.frame("Variable_MC"=c("WTemp_C", "SpCond_uScm", "TP_mgL_LAG", "Micro_mcyE_cp100mL_LAG", "Plank_mcyE_cp100mL_LAG", "WindDirInst_deg", "LkLevelChg14day", "LkLevelChg24_Ave7day",  "LkLevel_dev_springave"))

step(model3_MC, direction="backward")

model4_MIX <-lm(ELISA_MC_ANA_SXT~ WTemp_C + Secchi_meters + pH + SpCond_uScm + TP_mgL_LAG + NtoP_ratio_LAG + Micro_mcyE_cp100mL_LAG + Plank_mcyE_cp100mL_LAG + anaC_cp100mL_LAG + sxtA_cp100mL_LAG + WindSpInst_mph + WindDirInst_deg + WindSpAnt24_mph + WindDirAnt24_deg + RainD_1 + Sum14d_precip + BarPressInst_inhg + changeBP + LkLevelChg14day + LkLevelChg24_Ave7day + LkLevelChg24_Ave7dayABS + LkLevel_dev_springave + PAR_1dSUM, data=MIX_clean4)

step(model4_MIX, direction="backward")

model5_MIX <- lm(ELISA_MC_ANA_SXT~WTemp_C + SpCond_uScm + TP_mgL_LAG + Micro_mcyE_cp100mL_LAG + Plank_mcyE_cp100mL_LAG + anaC_cp100mL_LAG + sxtA_cp100mL_LAG + WindDirInst_deg + LkLevelChg14day + LkLevelChg24_Ave7day + LkLevel_dev_springave, data=MIX_clean4)

step(model5_MIX, direction="backward")

Table5 = data.frame("Variable_MIX"=c("WTemp_C", "SpCond_uScm", "TP_mgL_LAG", "Micro_mcyE_cp100mL_LAG", "Plank_mcyE_cp100mL_LAG", "anaC_cp100mL_LAG", "sxtA_cp100mL_LAG", "WindDirInst_deg", "LkLevelChg14day", "LkLevelChg24_Ave7day",  "LkLevel_dev_springave"))

```

##Final Variables
We did the step backwards algorithm and got a multiple linear regression model with 4 variables. The article uses 6 variables so our model was missing WT and WindDir. It makes sense that these weren't in our model because when we were originally running the VIF test those two had high VIF values. We didn't understand why they were in the final model but We added these two variables to our model. 


```{r}
MIX_clean4$WindDirInst_deg = MIX_clean4$WindDirInst_deg+0.0001

t_WTemp_C = (MC_clean3$WTemp_C)^-1
t_TP = (MC_clean3$TP_mgL_LAG)^2
t_Micro = (MC_clean3$Micro_mcyE_cp100mL_LAG)^(1/2)
t_Plank = (MC_clean3$Plank_mcyE_cp100mL_LAG)^(1/4)
final_MC_model = lm(ELISA_microcystin_ugL ~ t_WTemp_C + t_TP + t_Micro + t_Plank + WindDirInst_deg + LkLevelChg24_Ave7day, data = MC_clean3)
summary(final_MC_model)

AICc(final_MC_model, return.K = FALSE)
press(final_MC_model, as.R2 = FALSE)

t_ana = (MIX_clean4$anaC_cp100mL_LAG)^-1
print(t_ana)
t_sxt = sqrt(MIX_clean4$sxtA_cp100mL_LAG)
print(t_sxt)
t_LL = (MIX_clean4$LkLevelChg14day)^-1
print(t_LL)
final_MIX_model = lm(ELISA_MC_ANA_SXT ~ t_TP + t_Plank + t_ana + t_sxt + WindDirInst_deg + t_LL, data = MIX_clean4)
summary(final_MIX_model)

AICc(final_MIX_model, return.K = FALSE)
press(final_MIX_model, as.R2 = FALSE)

print(MC_clean3$ELISA_microcystin_ugL)
pred_MC = predict(final_MC_model, newdata = MC_clean3)
print(pred_MC)

print(MIX_clean4$ELISA_MC_ANA_SXT)

pred_MIX = predict(final_MIX_model, newdata = MIX_clean4)
print(pred_MIX)

Final_table = data.frame(
  Model = c("Comprehensive MC", "Comprehensive MIX"), 
  AICc = c(80.53, 340.13), 
  PRESS = c(15.1, 2487.38), 
  R2 = c(0.84, 0.84), 
  Sensitivity = c(1, 1), 
  Specificity = c(0.60, 0.95)
)
```
The first thing we noticed about the paper that could have been improved was table 2. In table 2, they stated that each site ID had a sample size of 41 which would be the raw data that we were given. If we produced the same statistics with the data we were given, we got a lot of NAs for our results. The paper didn’t address this issue in their paper, so we were unable to create the table with the same numbers of as they had.
Another problem that we ran into was with table 3. In table 3, we were unable to reproduce the same minimums that they had in their table. This is because the paper had a benchmark for how low they went for certain variables. With Anatoxin-a, the low point was 0.15 and wouldn’t go lower than that yet their minimum was <0.30. We didn’t really understand this out come and weren’t able to reproduce it in our table.
The paper was very clear what their variables were in their final model. We were able to follow closely how they removed about half of the variables. We ran a linear regression model with 25 variables still left. The paper was unclear if they did this or if there was another reason they eliminated some of their variables. We thought running a linear model with 25 variables was a little much but could be possible. There were also two variables that the paper kept when we wanted to remove due to their high VIF values. The paper didn’t address this or explain why they decided to keep these variables in their final model. In this step we had to jump to their final variables because they weren’t clear why they kept certain variables even though the data gave us a reason to remove them.
The graphs played a big role in understanding the threshold for both the MC and MIX data. This part was very easy to follow to decide the sensitivity and specificity of our data. The visual and description made for an easy-to-follow path in our analysis. The table were able to give us specific numbers to strive for, but the graph gave us a visual of what we wanted to reproduce. 


The audience plays a big part in how you write a paper and what you include in it. In this paper we would want to have more a step-by-step process of how they cleaned their data and got to their final variables. If this paper was for a statistical audience with a significant amount of statistic knowledge, the paper should include this part. It’s not important for a general audience but it would help if someone would like to reproduce the data. Also explain why certain variables were kept if the data specifies otherwise. This helps inform the reader about key information to keep in their data. Having this process of how they cleaned the data or how they got to their final model would be helpful when someone goes to reproduce the data. Having tables and graphs are key to a good research paper. Tables are helpful in organizing your findings and displaying them all in one spot. It makes it easy for the readers to find. I think it’s also important to have a key in the tables. Explain what certain variables are and why the data statistics were either altered a little or if the data was rare. Also having graphs helps with explaining the data without words. It’s a lot easier for non-statistics people to see visuals and understand compared to reading and trying to grasp an understanding. These four things play a big part in having a well-established paper.

